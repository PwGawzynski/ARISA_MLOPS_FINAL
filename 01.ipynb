{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ed51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost matplotlib pandas scikit-learn kaggle optuna ipywidgets kaleido shap jupyterlab-rise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4926311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!dir ../../../home/vscode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "125437f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "container_check = os.getenv(\"iscontainer\")\n",
    "if container_check==\"y\":\n",
    "    config_dir = Path(\"/home/vscode/.config/kaggle\")\n",
    "    config_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(config_dir / \"kaggle.json\", \"w\") as dst:\n",
    "        with open(\"./kaggle.json\", \"r\") as src:\n",
    "            dst.write(src.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f7ff8",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e2caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "\n",
    "\n",
    "dataset_name = \"arshid/iris-flower-dataset\"\n",
    "download_folder = Path(\"data/iris-prediction\")\n",
    "download_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "api.dataset_download_files(dataset_name, path=str(download_folder), unzip=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f6f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir \"./data/iris-prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1409f7",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59859b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(download_folder / \"iris.csv\")\n",
    "\n",
    "df.head(5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4239d",
   "metadata": {},
   "source": [
    "# One-hot encoding categorical non-order features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c2ef3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "hot_encoder = OneHotEncoder(drop='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a87544",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f16e739d",
   "metadata": {},
   "source": [
    "# Pipeline for transforming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "    ],\n",
    "    remainder='passthrough'  \n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "encoded_data = preprocessor.fit_transform(df)\n",
    "\n",
    "encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3344e7b9",
   "metadata": {},
   "source": [
    "# Creation of a data frame from transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135892c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = pd.DataFrame(\n",
    "  encoded_data,\n",
    "  columns=preprocessor.get_feature_names_out())\n",
    "\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e459ec76",
   "metadata": {},
   "source": [
    "# Division into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(transformed_df, test_size=0.2, random_state=42)\n",
    "\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aadb26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.pop(\"remainder__species\")\n",
    "X_train = df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0227db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e872c4e",
   "metadata": {},
   "source": [
    "# Automatic hyperparameter optimization for CatBoostClassifier using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "outfolder = Path(\"results\")\n",
    "outfolder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if isinstance(y_train, (pd.Series, pd.DataFrame)):\n",
    "     y_train_np = y_train.values.ravel()\n",
    "elif isinstance(y_train, list):\n",
    "     y_train_np = np.array(y_train)\n",
    "else:\n",
    "     y_train_np = y_train\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train_np)\n",
    "\n",
    "best_params_path = outfolder / \"best_params.pkl\"\n",
    "\n",
    "if not best_params_path.is_file():\n",
    "    X_train_opt, X_val_opt, y_train_opt_encoded, y_val_opt_encoded = train_test_split(X_train, y_train_encoded, test_size=0.25, random_state=42)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"depth\": trial.suggest_int(\"depth\", 2, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.3, log=True),\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-5, 100.0, log=True),\n",
    "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.01, 1.0),\n",
    "            \"random_strength\": trial.suggest_float(\"random_strength\", 1e-5, 100.0, log=True),\n",
    "            \"loss_function\": \"MultiClass\",\n",
    "            \"eval_metric\": \"MultiClass\"\n",
    "        }\n",
    "        model = CatBoostClassifier(**params, verbose=0, random_state=42)\n",
    "        model.fit(X_train_opt, y_train_opt_encoded,\n",
    "                  eval_set=(X_val_opt, y_val_opt_encoded),\n",
    "                  early_stopping_rounds=50,\n",
    "                  verbose=0)\n",
    "        return model.get_best_score()[\"validation\"][\"MultiClass\"]\n",
    "\n",
    "    study_name = \"catboost-multi-optimization\"\n",
    "    storage_name = f\"sqlite:///{study_name}.db\"\n",
    "\n",
    "    print(f\"Creating/loading Optuna study '{study_name}' from '{storage_name}'\")\n",
    "    study = optuna.create_study(study_name=study_name, storage=storage_name, direction=\"minimize\", load_if_exists=True)\n",
    "\n",
    "    print(\"Starting Optuna optimization...\")\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    print(\"Optimization finished.\")\n",
    "    print(\"Best trial:\")\n",
    "    print(\" Value: \", study.best_trial.value)\n",
    "    print(\" Params: \")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "    best_params = study.best_params\n",
    "    joblib.dump(best_params, best_params_path)\n",
    "    params = best_params\n",
    "else:\n",
    "    print(\"Loading best parameters from file.\")\n",
    "    params = joblib.load(best_params_path)\n",
    "\n",
    "print(\"Best Parameters for CV:\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0afa9b",
   "metadata": {},
   "source": [
    "# Cross-validation of CatBoostClassifier with optimized parameters and saving results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9e100c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best parameters from file.\n",
      "Parameters used for CV: {'depth': 2, 'learning_rate': 0.0860980163836657, 'iterations': 233, 'l2_leaf_reg': 0.04377587811072853, 'bagging_temperature': 0.35678838592729784, 'random_strength': 0.10944176769690127, 'loss_function': 'MultiClass', 'eval_metric': 'MultiClass', 'custom_metric': ['F1:macro', 'F1:weighted']}\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "outfolder = Path(\"results\")\n",
    "outfolder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    X_train_processed = X_train\n",
    "else:\n",
    "    X_train_processed = pd.DataFrame(X_train) # Ensure X_train is a DataFrame for consistency\n",
    "\n",
    "if isinstance(y_train, (pd.Series, pd.DataFrame)):\n",
    "     y_train_np = y_train.values.ravel()\n",
    "elif isinstance(y_train, list):\n",
    "     y_train_np = np.array(y_train)\n",
    "else:\n",
    "     y_train_np = y_train\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train_np)\n",
    "\n",
    "best_params_path = outfolder / \"best_params.pkl\"\n",
    "\n",
    "if not best_params_path.is_file():\n",
    "    X_train_opt, X_val_opt, y_train_opt_encoded, y_val_opt_encoded = train_test_split(X_train_processed, y_train_encoded, test_size=0.25, random_state=42)\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"depth\": trial.suggest_int(\"depth\", 2, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.3, log=True),\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-5, 100.0, log=True),\n",
    "            \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.01, 1.0),\n",
    "            \"random_strength\": trial.suggest_float(\"random_strength\", 1e-5, 100.0, log=True),\n",
    "            \"loss_function\": \"MultiClass\", # Fixed parameter in objective\n",
    "            \"eval_metric\": \"MultiClass\"     # Fixed parameter for evaluation in objective\n",
    "        }\n",
    "        model = CatBoostClassifier(**params, verbose=0, random_state=42)\n",
    "        model.fit(X_train_opt, y_train_opt_encoded,\n",
    "                  eval_set=(X_val_opt, y_val_opt_encoded),\n",
    "                  early_stopping_rounds=50,\n",
    "                  verbose=0)\n",
    "        return model.get_best_score()[\"validation\"][\"MultiClass\"]\n",
    "\n",
    "    study_name = \"catboost-multi-optimization\"\n",
    "    storage_name = f\"sqlite:///{study_name}.db\"\n",
    "\n",
    "    print(f\"Creating/loading Optuna study '{study_name}' from '{storage_name}'\")\n",
    "    study = optuna.create_study(study_name=study_name, storage=storage_name, direction=\"minimize\", load_if_exists=True)\n",
    "\n",
    "    print(\"Starting Optuna optimization...\")\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    print(\"Optimization finished.\")\n",
    "    print(\"Best trial:\")\n",
    "    print(\" Value: \", study.best_trial.value)\n",
    "    print(\" Params: \")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "    best_params = study.best_params\n",
    "    joblib.dump(best_params, best_params_path)\n",
    "    params = best_params\n",
    "else:\n",
    "    print(\"Loading best parameters from file.\")\n",
    "    params = joblib.load(best_params_path)\n",
    "\n",
    "# --- FIX: Add loss_function back as it's required for cv and might not be saved by Optuna ---\n",
    "params[\"loss_function\"] = \"MultiClass\"\n",
    "# --- Add other required parameters for CV / reporting ---\n",
    "params[\"eval_metric\"] = \"MultiClass\"\n",
    "\n",
    "\n",
    "print(\"Parameters used for CV:\", params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042d56a",
   "metadata": {},
   "source": [
    "# Plotting cross-validation F1 score with error bands using Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0410653e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting CatBoost CV...\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "catboost/private/libs/options/loss_description.cpp:36: Invalid metric description, it should be in the form \"metric_name:param1=value1;...;paramN=valueN\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m Pool(X_train_processed, y_train_encoded)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting CatBoost CV...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cv(\n\u001b[1;32m      6\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m      7\u001b[0m     pool\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m      8\u001b[0m     fold_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      9\u001b[0m     partition_random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     10\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCV finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(cv_results\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/catboost/core.py:6980\u001b[0m, in \u001b[0;36mcv\u001b[0;34m(pool, params, dtrain, iterations, num_boost_round, fold_count, nfold, inverted, partition_random_seed, seed, shuffle, logging_level, stratified, as_pandas, metric_period, verbose, verbose_eval, plot, plot_file, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, metric_update_interval, folds, type, return_models, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   6978\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_fixup(log_cout, log_cerr), plot_wrapper(plot, plot_file\u001b[38;5;241m=\u001b[39mplot_file, plot_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCross-validation plot\u001b[39m\u001b[38;5;124m'\u001b[39m, train_dirs\u001b[38;5;241m=\u001b[39mplot_dirs):\n\u001b[1;32m   6979\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_models:\n\u001b[0;32m-> 6980\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _cv(\n\u001b[1;32m   6981\u001b[0m             params,\n\u001b[1;32m   6982\u001b[0m             pool,\n\u001b[1;32m   6983\u001b[0m             fold_count,\n\u001b[1;32m   6984\u001b[0m             inverted,\n\u001b[1;32m   6985\u001b[0m             partition_random_seed,\n\u001b[1;32m   6986\u001b[0m             shuffle,\n\u001b[1;32m   6987\u001b[0m             stratified,\n\u001b[1;32m   6988\u001b[0m             metric_update_interval,\n\u001b[1;32m   6989\u001b[0m             as_pandas,\n\u001b[1;32m   6990\u001b[0m             folds,\n\u001b[1;32m   6991\u001b[0m             \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   6992\u001b[0m             return_models\n\u001b[1;32m   6993\u001b[0m         )\n\u001b[1;32m   6994\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6995\u001b[0m         results, cv_models \u001b[38;5;241m=\u001b[39m _cv(\n\u001b[1;32m   6996\u001b[0m             params,\n\u001b[1;32m   6997\u001b[0m             pool,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7007\u001b[0m             return_models\n\u001b[1;32m   7008\u001b[0m         )\n",
      "File \u001b[0;32m_catboost.pyx:5880\u001b[0m, in \u001b[0;36m_catboost._cv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:5912\u001b[0m, in \u001b[0;36m_catboost._cv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: catboost/private/libs/options/loss_description.cpp:36: Invalid metric description, it should be in the form \"metric_name:param1=value1;...;paramN=valueN\""
     ]
    }
   ],
   "source": [
    "# Use the processed DataFrame and encoded labels for CV\n",
    "data = Pool(X_train_processed, y_train_encoded)\n",
    "\n",
    "print(\"\\nStarting CatBoost CV...\")\n",
    "cv_results = cv(\n",
    "    params=params,\n",
    "    pool=data,\n",
    "    fold_count=5,\n",
    "    partition_random_seed=42,\n",
    "    shuffle=True,\n",
    "    verbose=True,\n",
    "    early_stopping_rounds=50,\n",
    ")\n",
    "\n",
    "print(\"CV finished.\")\n",
    "print(cv_results.head())\n",
    "\n",
    "cv_results.to_csv(outfolder / \"cv_results.csv\", index=False)\n",
    "print(f\"CV results saved to {outfolder / 'cv_results.csv'}\")\n",
    "\n",
    "if 'test-MultiClass-mean' in cv_results.columns:\n",
    "    best_iter_idx = cv_results['test-MultiClass-mean'].idxmin()\n",
    "    best_iterations = cv_results.loc[best_iter_idx, 'iterations']\n",
    "    print(f\"\\nBest number of iterations found from CV (based on MultiClass): {best_iterations}\")\n",
    "\n",
    "    final_model_params = params.copy()\n",
    "    final_model_params.pop('iterations', None) \n",
    "    final_model_params['n_estimators'] = best_iterations \n",
    "\n",
    "    # Optional: Remove eval_metric and custom_metric if they aren't needed for final training output\n",
    "    final_model_params.pop('eval_metric', None)\n",
    "    final_model_params.pop('custom_metric', None)\n",
    "\n",
    "\n",
    "    print(\"\\nTraining final model on full training data...\")\n",
    "    final_model = CatBoostClassifier(\n",
    "        **final_model_params,\n",
    "        random_state=42,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Fit the final model on the *entire* encoded training data (using the processed DataFrame)\n",
    "    final_model.fit(X_train_processed, y_train_encoded)\n",
    "\n",
    "    print(\"Final model training finished.\")\n",
    "\n",
    "    final_model_path = outfolder / \"final_catboost_model.joblib\"\n",
    "    joblib.dump(final_model, final_model_path)\n",
    "    print(f\"Final model saved to {final_model_path}\")\n",
    "else:\n",
    "     print(\"\\nCould not determine best iterations from CV results (MultiClass column not found?). Skipping final model training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee790079",
   "metadata": {},
   "source": [
    "# Plotting cross-validation Logloss with error bands using Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c246bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add mean performance line\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=cv_results[\"iterations\"], y=cv_results[\"test-Logloss-mean\"], mode=\"lines\", name=\"Mean logloss\", line=dict(color=\"blue\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add shaded error region\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=pd.concat([cv_results[\"iterations\"], cv_results[\"iterations\"][::-1]]),\n",
    "        y=pd.concat([cv_results[\"test-Logloss-mean\"]+cv_results[\"test-Logloss-std\"], \n",
    "                     cv_results[\"test-Logloss-mean\"]-cv_results[\"test-Logloss-std\"]]),\n",
    "        fill=\"toself\", \n",
    "        fillcolor=\"rgba(0, 0, 255, 0.2)\",\n",
    "        line=dict(color=\"rgba(255, 255, 255, 0)\"),\n",
    "        showlegend=False\n",
    "    )\n",
    ")\n",
    "\n",
    "# Customize layout\n",
    "fig.update_layout(\n",
    "    title=\"Cross-Validation (N=5) Mean Logloss with Error Bands\",\n",
    "    xaxis_title=\"Training Steps\",\n",
    "    yaxis_title=\"Logloss\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(outfolder / \"test_logloss.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5592d",
   "metadata": {},
   "source": [
    "# Final training of the CatBoost model and saving the model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    verbose_eval=50,\n",
    "    early_stopping_rounds=50,\n",
    "    use_best_model=False,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "model.save_model(outfolder / 'catboost_model_stroke_prediction.cbm')\n",
    "joblib.dump(params, outfolder / 'model_params.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99896bbb",
   "metadata": {},
   "source": [
    "# Generating predictions on the test dataset using the trained CatBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c510d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, log_loss\n",
    "\n",
    "model.predict(df_test)\n",
    "preds = model.predict(df_test[X_train.columns])\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018bdc85",
   "metadata": {},
   "source": [
    "# SHAP analysis for feature importance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598422ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(df_test)\n",
    "\n",
    "shap.summary_plot(shap_values, df_test, show=False)\n",
    "plt.savefig(outfolder / \"test_shap_overall.png\")\n",
    "\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"target\"] = preds\n",
    "df_test.to_csv(outfolder / \"predictions.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "     \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
